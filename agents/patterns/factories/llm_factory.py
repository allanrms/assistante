"""
Factory para cria√ß√£o de LLMs e Embeddings.

Seguindo melhores pr√°ticas da documenta√ß√£o LangChain:
- Configura√ß√µes consistentes (timeout, max_retries)
- Valida√ß√£o de par√¢metros
- Type hints apropriados
- Logs estruturados
- Tratamento de erros robusto
"""

from uuid import UUID
from typing import List, Optional

from django.conf import settings
from langchain.agents import create_agent
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.embeddings import Embeddings
from langchain_core.language_models import BaseChatModel

from agents.models import Agent


class PaddedEmbeddings(Embeddings):
    """
    Wrapper para embeddings que adiciona padding com zeros para atingir dimens√£o alvo.

    Usado para permitir embeddings de diferentes dimens√µes no mesmo banco de dados pgvector.
    - Google: 768 dims ‚Üí 1536 dims (padding com zeros)
    - OpenAI: 1536 dims ‚Üí 1536 dims (sem padding)
    """

    def __init__(self, base_embeddings: Embeddings, target_dim: int = 1536, provider: str = 'openai'):
        """
        Args:
            base_embeddings: Embedding base (OpenAI ou Google)
            target_dim: Dimens√£o alvo (padr√£o: 1536 para compatibilidade com banco)
            provider: Nome do provider ('openai' ou 'google')
        """
        self.base_embeddings = base_embeddings
        self.target_dim = target_dim
        self.provider = provider

    def _pad_vector(self, vector: List[float]) -> List[float]:
        """Adiciona padding com zeros se necess√°rio"""
        current_dim = len(vector)
        if current_dim < self.target_dim:
            # Adicionar zeros ao final
            padding = [0.0] * (self.target_dim - current_dim)
            return vector + padding
        return vector

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embeda m√∫ltiplos documentos com padding"""
        vectors = self.base_embeddings.embed_documents(texts)
        return [self._pad_vector(v) for v in vectors]

    def embed_query(self, text: str) -> List[float]:
        """Embeda uma query com padding"""
        vector = self.base_embeddings.embed_query(text)
        return self._pad_vector(vector)

class LLMFactory:
    """Factory para cria√ß√£o din√¢mica de agentes LangChain.

    Cria LLMs, Embeddings e Agentes completos baseados na configura√ß√£o
    do modelo Agent do Django. Suporta m√∫ltiplos providers:
    - OpenAI (GPT-4, GPT-3.5)
    - Anthropic (Claude)
    - Google (Gemini)

    Attributes:
        agent: Configura√ß√£o do Agent (Django model)
        contact_id: ID do contato (opcional)
        tools_factory: Factory de ferramentas (opcional)
        evolution_instance: Inst√¢ncia Evolution (opcional)
        llm: Modelo LLM criado
        embeddings: Modelo de embeddings criado
        tools: Lista de ferramentas
        langchain_agent: Agente LangChain completo

    Example:
        >>> from agents.models import Agent
        >>> agent_config = Agent.objects.get(name="google")
        >>> factory = LLMFactory(agent=agent_config)
        >>> response = factory.llm.invoke("Hello!")
    """

    def __init__(
        self,
        agent: Agent,
        contact_id: Optional[UUID] = None,
        tools_factory: Optional[callable] = None,
        evolution_instance: Optional[object] = None,
        create_agent: bool = True
    ):
        """Inicializa factory e cria todos os componentes.

        Args:
            agent: Configura√ß√£o do modelo LLM (Django Agent model)
            contact_id: ID do contato para injetar nas ferramentas
            tools_factory: Fun√ß√£o que cria ferramentas (ex: create_reception_tools)
            evolution_instance: Inst√¢ncia Evolution para envio de mensagens/arquivos
            create_agent: Se False, apenas cria LLM e embeddings (√∫til para tasks)

        Raises:
            Exception: Se houver erro na cria√ß√£o de qualquer componente
        """
        print(f"üè≠ [Factory] Inicializando LLMFactory para agent: {agent.name}")

        try:
            self.agent = agent
            self.contact_id = contact_id
            self.tools_factory = tools_factory
            self.evolution_instance = evolution_instance

            # Criar componentes na ordem correta
            self.llm = self._create_llm()
            self.embeddings = self._create_embeddings()

            # Criar tools e agent apenas se necess√°rio
            if create_agent:
                self.tools = self._create_tools()
            else:
                self.tools = []
                self.langchain_agent = None
                print(f"‚ö†Ô∏è  [Factory] Modo simplificado (apenas LLM + Embeddings)")

            print(f"‚úÖ [Factory] Inicializa√ß√£o completa!")

        except Exception as e:
            print(f"‚ùå [Factory] Erro ao inicializar: {str(e)}")
            import traceback
            traceback.print_exc()
            raise e

    def _create_llm(self) -> BaseChatModel:
        """Cria modelo LLM com configura√ß√µes robustas.

        Aplica configura√ß√µes consistentes para todos os providers:
        - timeout: 30 segundos (evita travamentos)
        - max_retries: 2 tentativas (resili√™ncia)
        - Valida√ß√£o de par√¢metros

        Returns:
            BaseChatModel: LLM configurado (OpenAI, Anthropic ou Google)

        Raises:
            ValueError: Se configura√ß√£o do agent for inv√°lida
        """
        provider = self.agent.name.lower() if self.agent.name else ""
        model_name = self.agent.model or ""

        # Valida√ß√µes b√°sicas
        if not model_name:
            print(f"‚ö†Ô∏è  [LLM] Modelo n√£o especificado, usando defaults")

        # Par√¢metros comuns para todos os modelos
        common_params = {
            "temperature": self.agent.temperature if hasattr(self.agent, 'temperature') else 0.5,
            "timeout": 30.0,  # 30 segundos de timeout
            "max_retries": 2,  # At√© 2 tentativas em caso de falha
        }

        print(f"ü§ñ [LLM] Criando: {provider.title()} - Modelo: {model_name}")
        print(f"‚öôÔ∏è  [LLM] Config: temp={common_params['temperature']}, timeout={common_params['timeout']}s, retries={common_params['max_retries']}")

        if provider == "openai":
            return ChatOpenAI(
                model=model_name or "gpt-4o",
                temperature=common_params["temperature"],
                max_tokens=self.agent.max_tokens if hasattr(self.agent, 'max_tokens') and self.agent.max_tokens else 2000,
                top_p=self.agent.top_p if hasattr(self.agent, 'top_p') else 1.0,
                presence_penalty=self.agent.presence_penalty if hasattr(self.agent, 'presence_penalty') else 0.0,
                frequency_penalty=self.agent.frequency_penalty if hasattr(self.agent, 'frequency_penalty') else 0.0,
                timeout=common_params["timeout"],
                max_retries=common_params["max_retries"],
                api_key=getattr(settings, 'OPENAI_API_KEY', '')
            )

        elif provider == "anthropic":
            return ChatAnthropic(
                model=model_name or "claude-3-5-sonnet-20241022",
                temperature=common_params["temperature"],
                max_tokens=self.agent.max_tokens if hasattr(self.agent, 'max_tokens') and self.agent.max_tokens else 4096,
                top_p=self.agent.top_p if hasattr(self.agent, 'top_p') else 1.0,
                timeout=common_params["timeout"],
                max_retries=common_params["max_retries"],
                api_key=getattr(settings, 'ANTHROPIC_API_KEY', '')
            )

        elif provider == "google":
            return ChatGoogleGenerativeAI(
                model=model_name or "gemini-2.0-flash-exp",
                temperature=common_params["temperature"],
                max_tokens=self.agent.max_tokens if hasattr(self.agent, 'max_tokens') and self.agent.max_tokens else 1000,
                top_p=self.agent.top_p if hasattr(self.agent, 'top_p') else 1.0,
                timeout=common_params["timeout"],
                max_retries=common_params["max_retries"],
                google_api_key=getattr(settings, 'GOOGLE_API_KEY', '')
            )

        else:
            # Fallback para OpenAI
            print(f"‚ö†Ô∏è  [LLM] Provider desconhecido '{provider}', usando OpenAI como fallback")
            return ChatOpenAI(
                model=model_name or "gpt-4o",
                temperature=common_params["temperature"],
                max_tokens=2000,
                timeout=common_params["timeout"],
                max_retries=common_params["max_retries"],
                api_key=getattr(settings, 'OPENAI_API_KEY', '')
            )

    def _create_embeddings(self) -> PaddedEmbeddings:
        """Cria modelo de Embeddings com dimens√£o padronizada.

        O banco usa dimens√£o fixa de 1536 (compatibilidade pgvector):
        - OpenAI: 1536 dims nativo (sem padding necess√°rio)
        - Google: 768 dims ‚Üí 1536 dims (padding autom√°tico)
        - Anthropic: Usa OpenAI embeddings como padr√£o

        Returns:
            PaddedEmbeddings: Embeddings configurado com padding autom√°tico

        Note:
            O wrapper PaddedEmbeddings adiciona zeros automaticamente
            se a dimens√£o for menor que 1536.
        """
        provider = self.agent.name.lower() if self.agent.name else ""

        print(f"üî¢ [Embeddings] Criando para provider: {provider.title()}")

        if provider == "google":
            print(f"üìä [Embeddings] Google: 768 dims ‚Üí 1536 (com padding)")
            try:
                base_embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/embedding-001",
                    google_api_key=getattr(settings, 'GOOGLE_API_KEY', '')
                )
                return PaddedEmbeddings(base_embeddings, target_dim=1536, provider='google')
            except Exception as e:
                print(f"‚ö†Ô∏è  [Embeddings] Erro ao criar Google Embeddings: {str(e)}")
                print(f"‚ö†Ô∏è  [Embeddings] Fallback para OpenAI")
                # Fallback para OpenAI
                base_embeddings = OpenAIEmbeddings(
                    model="text-embedding-3-small",
                    api_key=getattr(settings, 'OPENAI_API_KEY', '')
                )
                return PaddedEmbeddings(base_embeddings, target_dim=1536, provider='openai')
        else:
            # OpenAI como padr√£o (openai, anthropic, outros)
            print(f"üìä [Embeddings] OpenAI: 1536 dims (nativo)")
            try:
                base_embeddings = OpenAIEmbeddings(
                    model="text-embedding-3-small",
                    api_key=getattr(settings, 'OPENAI_API_KEY', '')
                )
                return PaddedEmbeddings(base_embeddings, target_dim=1536, provider='openai')
            except Exception as e:
                print(f"‚ùå [Embeddings] Erro ao criar OpenAI Embeddings: {str(e)}")
                raise

    def _create_tools(self):
        """
        Cria ferramentas dispon√≠veis para o agente.
        Se tools_factory foi fornecido, usa ele. Caso contr√°rio, retorna lista vazia.

        Returns:
            Lista de ferramentas LangChain
        """
        if self.tools_factory and self.contact_id:
            # Usar factory personalizado (ex: create_reception_tools)
            evolution_instance_id = self.evolution_instance.id if self.evolution_instance else None

            tools = self.tools_factory(
                contact_id=self.contact_id,
                # evolution_instance_id=evolution_instance_id
            )

            return tools
        else:
            print('‚ö†Ô∏è Nenhuma ferramenta criada (tools_factory ou contact_id n√£o fornecidos)')
            return []

